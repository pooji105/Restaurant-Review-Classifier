# -*- coding: utf-8 -*-
"""Restaurant_Review_Classifier

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M5CrwuZPmdChinCQMx4jRZYmzOWGmuo6
"""

from google.colab import files

uploaded = files.upload()   # choose Restaurant_Reviews.tsv from your system

# Basic libraries
import numpy as np
import pandas as pd
import re
import pickle

# NLP libraries
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer

# ML libraries
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import BernoulliNB
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Load the TSV file (tab separated)
data = pd.read_csv('Restaurant_Reviews.tsv', sep='\t')

# See first few rows
data.head()

# Load the TSV file (tab separated)
data = pd.read_csv('Restaurant_Reviews.tsv', sep='\t')

# See first few rows
data.head()

ps = PorterStemmer()
stop_words = set(stopwords.words('english'))

corpus = []

for review in data['Review']:
    # 1. Keep only letters
    review = re.sub('[^a-zA-Z]', ' ', review)
    # 2. Lowercase
    review = review.lower()
    # 3. Split into words
    words = review.split()
    # 4. Remove stopwords & apply stemming
    words = [ps.stem(word) for word in words if word not in stop_words]
    # 5. Join back into one string
    cleaned_review = ' '.join(words)
    corpus.append(cleaned_review)

# See few cleaned reviews
corpus[:5]

data.info()
data['Liked'].value_counts()

ps = PorterStemmer()
stop_words = set(stopwords.words('english'))

corpus = []

for review in data['Review']:
    # 1. Keep only letters
    review = re.sub('[^a-zA-Z]', ' ', review)
    # 2. Lowercase
    review = review.lower()
    # 3. Split into words
    words = review.split()
    # 4. Remove stopwords & apply stemming
    words = [ps.stem(word) for word in words if word not in stop_words]
    # 5. Join back into one string
    cleaned_review = ' '.join(words)
    corpus.append(cleaned_review)

# See few cleaned reviews
corpus[:5]

# Convert text to numbers using TF-IDF
tfidf = TfidfVectorizer(max_features=1500)
X = tfidf.fit_transform(corpus).toarray()

# Target labels (0 = not liked, 1 = liked)
y = data['Liked'].values

X.shape, y.shape

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,   # 20% test
    random_state=0
)

X_train.shape, X_test.shape

model = BernoulliNB()
model.fit(X_train, y_train)

# Predict on test set
y_pred = model.predict(X_test)

# Accuracy
acc = accuracy_score(y_test, y_pred)
print("Accuracy:", acc)

# Optional: detailed metrics
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))

def clean_review(text):
    # Same cleaning steps as before
    text = re.sub('[^a-zA-Z]', ' ', text)
    text = text.lower()
    words = text.split()
    words = [ps.stem(word) for word in words if word not in stop_words]
    return ' '.join(words)

def predict_review(text):
    cleaned = clean_review(text)
    vec = tfidf.transform([cleaned]).toarray()
    pred = model.predict(vec)[0]
    if pred == 1:
        return "Positive (Liked)"
    else:
        return "Negative (Not liked)"

# Try some reviews
print(predict_review("The food was amazing and the staff were very friendly"))
print(predict_review("The service was too slow and the food was cold"))
print(predict_review("Not tasty and the texture was just nasty"))

# Save TF-IDF vectorizer
with open('tfidf_vectorizer.pkl', 'wb') as f:
    pickle.dump(tfidf, f)

# Save trained model
with open('sentiment_model.pkl', 'wb') as f:
    pickle.dump(model, f)

print("Saved model and vectorizer as .pkl files")

from google.colab import files

files.download('tfidf_vectorizer.pkl')
files.download('sentiment_model.pkl')

data['Liked'].value_counts().plot(kind='bar')

from wordcloud import WordCloud

models = {
    "BernoulliNB": BernoulliNB(),
    "Logistic Regression": LogisticRegression(),
    "SVM": LinearSVC(),
    "Random Forest": RandomForestClassifier()
}

from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.ensemble import RandomForestClassifier

from sklearn.neighbors import KNeighborsClassifier

models = {
    "BernoulliNB": BernoulliNB(),
    "Logistic Regression": LogisticRegression(max_iter=200),
    "SVM": LinearSVC(),
    "Random Forest": RandomForestClassifier(),
    "KNN": KNeighborsClassifier()
}

accuracy_results = {}

for name, clf in models.items():
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    accuracy_results[name] = acc
    print(f"{name} Accuracy: {acc:.4f}")

import matplotlib.pyplot as plt

plt.figure(figsize=(8,5))
plt.bar(accuracy_results.keys(), accuracy_results.values())
plt.xlabel("Models")
plt.ylabel("Accuracy")
plt.title("Model Accuracy Comparison")
plt.show()

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# New TF-IDF: more features + unigrams + bigrams
tfidf_v2 = TfidfVectorizer(
    max_features=3000,
    ngram_range=(1, 2),   # 1-gram and 2-gram
    min_df=2
)

X2 = tfidf_v2.fit_transform(corpus).toarray()
y2 = data['Liked'].values

X2_train, X2_test, y2_train, y2_test = train_test_split(
    X2, y2, test_size=0.2, random_state=0
)

X2_train.shape, X2_test.shape

from sklearn.svm import LinearSVC

best_acc = 0
best_C = None
best_model = None

for C in [0.1, 0.5, 1.0, 2.0]:
    clf = LinearSVC(C=C)
    clf.fit(X2_train, y2_train)
    y2_pred = clf.predict(X2_test)
    acc = accuracy_score(y2_test, y2_pred)
    print(f"LinearSVC  C={C} -> Accuracy={acc:.4f}")

    if acc > best_acc:
        best_acc = acc
        best_C = C
        best_model = clf

print("\nBest C:", best_C, "Best accuracy:", best_acc)